{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"2qMVn5gLriM1","outputId":"81111187-1721-4e36-80b2-477b28913e7b","executionInfo":{"status":"ok","timestamp":1709417554709,"user_tz":-120,"elapsed":237114,"user":{"displayName":"Marios Chartsias","userId":"08266621666467733398"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-14b039d0-d794-482c-ab8a-9ac7a2bf8e6d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-14b039d0-d794-482c-ab8a-9ac7a2bf8e6d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Object-Detection.v12i.yolov8.zip to Object-Detection.v12i.yolov8.zip\n","Uploaded file name: Object-Detection.v12i.yolov8.zip\n"]}],"source":["import yaml\n","from google.colab import files\n","\n","# Upload the file \"data.yaml\" from your local PC to Google Colab\n","uploaded = files.upload()\n","\n","# Get the filename from the uploaded dictionary\n","file_name = list(uploaded.keys())[0]\n","\n","print(\"Uploaded file name:\", file_name)"]},{"cell_type":"code","source":["file_name='Object-Detection.v11i.yolov8.zip'"],"metadata":{"id":"IzXk15NcdYOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":501,"status":"ok","timestamp":1709417565799,"user":{"displayName":"Marios Chartsias","userId":"08266621666467733398"},"user_tz":-120},"id":"s0cEOxYwPEOG","outputId":"226fd2c1-8f69-4225-9a69-b10f8f9e7f19"},"outputs":[{"output_type":"stream","name":"stdout","text":["Current directory: /content\n","Files extracted to: /content/Object-Detection.v12i.yolov8\n"]}],"source":["def setting():\n","  import locale\n","  #print(locale.getpreferredencoding())\n","\n","  def getpreferredencoding(do_setlocale = True):\n","      return \"UTF-8\"\n","  locale.getpreferredencoding = getpreferredencoding\n","\n","\n","import os\n","import zipfile\n","\n","#file_name=''\n","if(file_name == ''):\n","  file_name = 'ProjectTest.v9i.yolov8.zip'\n","# Get the current working directory\n","current_directory = os.getcwd()\n","print(\"Current directory:\", current_directory)\n","\n","# Path to the ZIP file\n","zip_file_path = '/content/'+file_name\n","\n","# Extract the contents of the ZIP file to a folder with the same name\n","output_folder = os.path.splitext(os.path.basename(zip_file_path))[0]\n","output_folder_path = os.path.join(current_directory, output_folder)\n","\n","# Create the output folder if it doesn't exist\n","if not os.path.exists(output_folder_path):\n","    os.makedirs(output_folder_path)\n","\n","# Extract the contents of the ZIP file into the output folder\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    zip_ref.extractall(output_folder_path)\n","\n","print(\"Files extracted to:\", output_folder_path)\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15379,"status":"ok","timestamp":1709417584700,"user":{"displayName":"Marios Chartsias","userId":"08266621666467733398"},"user_tz":-120},"id":"fdn0eVjaciNb","outputId":"4b013bdd-13e6-43e9-8048-6c704579d632"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.20 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.4/201.2 GB disk)\n"]}],"source":["%pip install ultralytics\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J8NrwAPqRsxk"},"outputs":[],"source":["!pwd #get the location\n","!yolo train model=yolov8n.pt data=/content/minimap.v2i.yolov8/data.yaml epochs=25 imgsz=640"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtQwPxPJs2q3","outputId":"b775c70d-277c-41a3-b3bf-cb6df4160e40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6.23M/6.23M [00:00<00:00, 182MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.20 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/Object-Detection.v12i.yolov8/data.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 755k/755k [00:00<00:00, 39.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Overriding model.yaml nc=80 with nc=20\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    755212  ultralytics.nn.modules.head.Detect           [20, [64, 128, 256]]          \n","Model summary: 225 layers, 3014748 parameters, 3014732 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Object-Detection.v12i.yolov8/train/labels... 93 images, 6 backgrounds, 0 corrupt: 100%|██████████| 93/93 [00:00<00:00, 988.10it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Object-Detection.v12i.yolov8/train/labels.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Object-Detection.v12i.yolov8/valid/labels... 31 images, 3 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<00:00, 696.85it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Object-Detection.v12i.yolov8/valid/labels.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000417, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"]}],"source":["#output_folder_path = '/content/ProjectTest.v9i.yolov8'\n","from ultralytics import YOLO\n","#max free imgsz=1620\n","\n","model = YOLO(\"yolov8n.pt\")\n","results = model.train(data=f'{output_folder_path}/data.yaml', epochs=20, imgsz=640)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7423,"status":"ok","timestamp":1709234507345,"user":{"displayName":"Marios Chartsias","userId":"08266621666467733398"},"user_tz":-120},"id":"H2Qdqyidrq3u","outputId":"5207b7f4-718b-4f33-f57d-bbefc2b6dff1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.19 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","Model summary (fused): 168 layers, 3009548 parameters, 0 gradients, 8.1 GFLOPs\n","\n","image 1/16 /content/Object-Detection.v12i.yolov8/test/images/2427_png.rf.c0fc2b1995e462c65535c8939833cef5.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 2 BattleOfSeaWindows, 1 ConfirmToBotQuestion, 1 MyShip, 1 TextFieldToBotQuestion, 1 chatButton, 1 fireDisabled, 1 island, 1 map, 1 ocrText, 119.0ms\n","image 2/16 /content/Object-Detection.v12i.yolov8/test/images/2644_png.rf.93ef1c73aa5354aab47aa02332ef0f05.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 2 BattleOfSeaWindows, 1 CenterMyBoat, 1 ConfirmToBotQuestion, 1 MyShip, 1 TextFieldToBotQuestion, 1 chatButton, 1 fireDisabled, 1 ocrText, 7.3ms\n","image 3/16 /content/Object-Detection.v12i.yolov8/test/images/3162_png.rf.d9b09f590dbeb1094ce59bd8d0bea2c8.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 2 BattleOfSeaWindows, 1 ConfirmToBotQuestion, 1 MyShip, 1 TextFieldToBotQuestion, 1 chatButton, 1 fireDisabled, 1 island, 1 map, 1 ocrText, 7.6ms\n","image 4/16 /content/Object-Detection.v12i.yolov8/test/images/EnemyClick2_png.rf.0a34b50974358667c4cffb566a51a64f.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 3 BattleOfSeaWindows, 1 CenterMyBoat, 1 EnemyClicked, 1 MyShip, 1 chatButton, 1 fireEnabled, 1 glitter, 1 glitterClicked, 3 islands, 1 map, 7.3ms\n","image 5/16 /content/Object-Detection.v12i.yolov8/test/images/MyBoat24_png.rf.da03d2d03a8add12e168beeb2f6a74c3.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 3 BattleOfSeaWindows, 1 CenterMyBoat, 1 EnemyClicked, 1 MyShip, 1 chatButton, 1 fireEnabled, 1 glitter, 2 islands, 1 map, 7.3ms\n","image 6/16 /content/Object-Detection.v12i.yolov8/test/images/MyBoat29_png.rf.5c4bd5b86d208f9d65598c43dd724696.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 3 BattleOfSeaWindows, 1 CenterMyBoat, 1 MyShip, 1 chatButton, 1 fireDisabled, 1 glitter, 2 islands, 1 map, 1 pointOfMoving, 7.2ms\n","image 7/16 /content/Object-Detection.v12i.yolov8/test/images/MyBoat35_png.rf.9615919f934aae592f95d841357f9720.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 3 BattleOfSeaWindows, 1 EnemyClicked, 1 MyShip, 1 chatButton, 1 fireDisabled, 1 glitterClicked, 1 map, 7.3ms\n","image 8/16 /content/Object-Detection.v12i.yolov8/test/images/MyBoat6_png.rf.67b2554e4d413a33cde648930469222d.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 3 BattleOfSeaWindows, 1 CenterMyBoat, 1 chatButton, 1 fireDisabled, 2 glitters, 2 glitterClickeds, 2 islands, 1 map, 7.6ms\n","image 9/16 /content/Object-Detection.v12i.yolov8/test/images/Null10_png.rf.d0690431a35e2f50baa0fdcb63f5cf3e.jpg: 1152x2016 (no detections), 7.4ms\n","image 10/16 /content/Object-Detection.v12i.yolov8/test/images/Null1_png.rf.3b2f80d6a464739675c46f73f240a540.jpg: 1152x2016 (no detections), 7.3ms\n","image 11/16 /content/Object-Detection.v12i.yolov8/test/images/clickedGlitter10_png.rf.77fdbf93696923e9acf92a934db10748.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 3 BattleOfSeaWindows, 1 CenterMyBoat, 1 MyShip, 1 chatButton, 1 fireDisabled, 4 glitters, 1 glitterClicked, 1 island, 1 map, 7.5ms\n","image 12/16 /content/Object-Detection.v12i.yolov8/test/images/clickedGlitter14_png.rf.5e129ef382389d1c790d7d18765f0413.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 3 BattleOfSeaWindows, 1 CenterMyBoat, 1 MyShip, 1 chatButton, 1 fireDisabled, 2 glitters, 1 glitterClicked, 1 island, 1 map, 7.4ms\n","image 13/16 /content/Object-Detection.v12i.yolov8/test/images/hiddenGlitter8_png.rf.d491a6f98b4438b3c23dac8c3ca5aece.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 3 BattleOfSeaWindows, 1 MyShip, 1 chatButton, 1 fireDisabled, 2 glitters, 2 islands, 1 map, 7.3ms\n","image 14/16 /content/Object-Detection.v12i.yolov8/test/images/screenshot20_png.rf.1d3abdf7c3a81f8cfd7ef75198384ae1.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 2 BattleOfSeaWindows, 1 CenterMyBoat, 1 MyShip, 1 chat, 1 chatButton, 1 fireDisabled, 1 glitter, 1 island, 1 map, 7.1ms\n","image 15/16 /content/Object-Detection.v12i.yolov8/test/images/screenshot7_png.rf.4754ccdcd762f0c087f87e83f3594b67.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 3 BattleOfSeaWindows, 1 CenterMyBoat, 1 chat, 1 chatButton, 1 fireDisabled, 1 glitter, 2 islands, 1 map, 7.6ms\n","image 16/16 /content/Object-Detection.v12i.yolov8/test/images/screenshot8_png.rf.13b73811e1be8b2f14f0be2af5449706.jpg: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 3 BattleOfSeaWindows, 1 CenterMyBoat, 1 chat, 1 chatButton, 1 fireDisabled, 1 glitter, 1 island, 1 map, 7.5ms\n","Speed: 16.2ms preprocess, 14.4ms inference, 37.3ms postprocess per image at shape (1, 3, 1152, 2016)\n","Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n","14 labels saved to runs/detect/predict2/labels\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}],"source":["setting()\n","!yolo task=detect mode=predict model='/content/runs/detect/train/weights/best.pt' conf=0.25 source='/content/Object-Detection.v12i.yolov8/test/images' save=True save_txt=True"]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load a pre-trained YOLOv8 model\n","model = YOLO('/content/runs/detect/train2/weights/best.pt')\n","\n","# Specify the source image\n","source = '/content/screenshot*.png'\n","\n","# Make predictions\n","results = model.predict(source, save=True, imgsz=300, conf=0.2)\n","\n","boxes = results[0].boxes.xyxy.cpu()\n","clss = results[0].boxes.cls.cpu().tolist()\n","Dictionary = results[0].names\n","# Extract bounding box dimensions\n","boxes = results[0].boxes.xywh.cpu()\n","for box,cls in zip(boxes,clss):\n","    print(\"***********\")\n","    x, y, w, h = box\n","    #print(f\"x={x}, y={y} and Width of Box:  w={w}, Height of Box: h={h}\")\n","    print(f\"cls={cls}->{Dictionary[cls]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7Ua0OfH1z5d","executionInfo":{"status":"ok","timestamp":1708864353287,"user_tz":-120,"elapsed":289,"user":{"displayName":"Marios Chartsias","userId":"08266621666467733398"}},"outputId":"27615f5c-50ae-41b8-8c8f-78ff206dafa8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","WARNING ⚠️ imgsz=[300] must be multiple of max stride 32, updating to [320]\n","image 1/1 /content/screenshot1.png: 192x320 1 Number4, 1 Number5, 1 Number7, 1 Number8, 15.9ms\n","Speed: 0.9ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 192, 320)\n","Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n","***********\n","cls=6.0->Number7\n","***********\n","cls=7.0->Number8\n","***********\n","cls=4.0->Number5\n","***********\n","cls=3.0->Number4\n"]}]},{"cell_type":"code","source":["def getText(screenshot_array_format,modelOCR=YOLO('/content/runs/detect/train2/weights/best.pt')):\n","    results = modelOCR.predict(screenshot_array_format,imgsz=640, conf=0.2)\n","    boxes = results[0].boxes.xyxy.cpu()\n","    clss = results[0].boxes.cls.cpu().tolist()\n","    Dictionary = results[0].names\n","    mapping = {}\n","    for box, cls in zip(boxes, clss):\n","        mapping[box[0]] = Dictionary[cls][-1]\n","        #print(f\"box={box[0]}, cls={cls}->{Dictionary[cls]}\")\n","\n","    sorted_dict = {k: v for k, v in sorted(mapping.items(), key=lambda item: item[0])}\n","    string=''\n","    for value in sorted_dict.values():\n","        string=string+value\n","    return string\n","\n","\n","getText(source)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"h8fPqJWrElf4","executionInfo":{"status":"ok","timestamp":1708861396162,"user_tz":-120,"elapsed":261,"user":{"displayName":"Marios Chartsias","userId":"08266621666467733398"}},"outputId":"552cadaf-55c1-42c9-c673-8658302eb332"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/screenshot1.png: 384x640 1 Number4, 1 Number5, 1 Number7, 1 Number8, 55.3ms\n","Speed: 1.2ms preprocess, 55.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"]},{"output_type":"execute_result","data":{"text/plain":["'5874'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["for result in results:\n","    print(results.index)\n","    for i, box in enumerate(result.boxes.xyxy):\n","        print(\"Bounding box:\", box)\n","\n","        # Extract coordinates of the detected object's bounding box\n","        x1, y1, x2, y2 = box[:4]\n","        print(\"Bounding box coordinates:\", x1, y1, x2, y2)\n","\n","        # Access the class label for the bounding box\n","        class_label = result.names[i]\n","        print(\"Class:\", class_label)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uMkL7kdS4lIL","executionInfo":{"status":"ok","timestamp":1708861311961,"user_tz":-120,"elapsed":288,"user":{"displayName":"Marios Chartsias","userId":"08266621666467733398"}},"outputId":"904f715f-7440-4683-c85a-a0d04af7d9b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<built-in method index of list object at 0x7a656b535bc0>\n","Bounding box: tensor([48.8191, 11.1394, 59.1070, 29.7945], device='cuda:0')\n","Bounding box coordinates: tensor(48.8191, device='cuda:0') tensor(11.1394, device='cuda:0') tensor(59.1070, device='cuda:0') tensor(29.7945, device='cuda:0')\n","Class: Number1\n","Bounding box: tensor([35.1990, 11.6475, 46.1495, 29.9655], device='cuda:0')\n","Bounding box coordinates: tensor(35.1990, device='cuda:0') tensor(11.6475, device='cuda:0') tensor(46.1495, device='cuda:0') tensor(29.9655, device='cuda:0')\n","Class: Number2\n","Bounding box: tensor([20.8811, 14.5520, 32.1943, 33.3263], device='cuda:0')\n","Bounding box coordinates: tensor(20.8811, device='cuda:0') tensor(14.5520, device='cuda:0') tensor(32.1943, device='cuda:0') tensor(33.3263, device='cuda:0')\n","Class: Number3\n","Bounding box: tensor([60.8163, 14.5301, 71.7158, 33.1125], device='cuda:0')\n","Bounding box coordinates: tensor(60.8163, device='cuda:0') tensor(14.5301, device='cuda:0') tensor(71.7158, device='cuda:0') tensor(33.1125, device='cuda:0')\n","Class: Number4\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","def plot_boxes_and_save(results, output_dir):\n","    for i, result in enumerate(results):\n","        # Create a new figure\n","        fig, ax = plt.subplots()\n","\n","        # Plot the image (assuming it's already loaded)\n","        # Replace 'result.image' with the actual image data if available\n","        ax.imshow(result.image)\n","\n","        # Plot each bounding box\n","        for box, name in zip(result.boxes.xyxy, result.names):\n","            x1, y1, x2, y2 = box[:4]\n","            width = x2 - x1\n","            height = y2 - y1\n","\n","            # Create a rectangle patch\n","            rect = patches.Rectangle((x1, y1), width, height, linewidth=1, edgecolor='r', facecolor='none')\n","\n","            # Add the rectangle patch to the Axes\n","            ax.add_patch(rect)\n","\n","            # Add class label as text\n","            ax.text(x1, y1, name, color='r', verticalalignment='top')\n","\n","        # Set axis off\n","        ax.axis('off')\n","\n","        # Save the figure as PNG\n","        plt.savefig(f'{output_dir}/box_{i}.png', bbox_inches='tight', pad_inches=0)\n","\n","        # Close the figure to release memory\n","        plt.close()\n","\n","# Example usage:\n","results = results  # Replace \"your_results_list\" with your actual results object\n","output_dir = '/content/plots'  # Directory to save the plots\n","\n","# Call the function to plot boxes and save as PNG\n","plot_boxes_and_save(results, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"qjlCq_DqEEO2","executionInfo":{"status":"error","timestamp":1708864394235,"user_tz":-120,"elapsed":30728,"user":{"displayName":"Marios Chartsias","userId":"08266621666467733398"}},"outputId":"2d364808-d788-402f-dab2-a5d1bb6653d1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'Results' object has no attribute 'image'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Attributes:\n        orig_img (numpy.ndarray): Original image as a numpy array.\n        orig_shape (tuple): Original image shape in (height, width) format.\n        boxes (Boxes, optional): Object containing detection bounding boxes.\n        masks (Masks, optional): Object containing detection masks.\n        probs (Probs, optional): Object containing class probabilities for classification tasks.\n        keypoints (Keypoints, optional): Object containing detected keypoints for each object.\n        speed (dict): Dictionary of preprocess, inference, and postprocess speeds (ms/image).\n        names (dict): Dictionary of class names.\n        path (str): Path to the image file.\n\n    Methods:\n        update(boxes=None, masks=None, probs=None, obb=None): Updates object attributes with new detection results.\n        cpu(): Returns a copy of the Results object with all tensors on CPU memory.\n        numpy(): Returns a copy of the Results object with all tensors as numpy arrays.\n        cuda(): Returns a copy of the Results object with all tensors on GPU memory.\n        to(*args, **kwargs): Returns a copy of the Results object with tensors on a specified device and dtype.\n        new(): Returns a new Results object with the same image, path, and names.\n        plot(...): Plots detection results on an input image, returning an annotated image.\n        show(): Show annotated results to screen.\n        save(filename): Save annotated results to file.\n        verbose(): Returns a log string for each task, detailing detections and classifications.\n        save_txt(txt_file, save_conf=False): Saves detection results to a text file.\n        save_crop(save_dir, file_name=Path(\"im.jpg\")): Saves cropped detection images.\n        tojson(normalize=False): Converts detection results to JSON format.\n    ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-20f12fc49ae0>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Call the function to plot boxes and save as PNG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mplot_boxes_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-20f12fc49ae0>\u001b[0m in \u001b[0;36mplot_boxes_and_save\u001b[0;34m(results, output_dir)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Plot the image (assuming it's already loaded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Replace 'result.image' with the actual image data if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Plot each bounding box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;34m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{name}' object has no attribute '{attr}'. See valid attributes below.\\n{self.__doc__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Results' object has no attribute 'image'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Attributes:\n        orig_img (numpy.ndarray): Original image as a numpy array.\n        orig_shape (tuple): Original image shape in (height, width) format.\n        boxes (Boxes, optional): Object containing detection bounding boxes.\n        masks (Masks, optional): Object containing detection masks.\n        probs (Probs, optional): Object containing class probabilities for classification tasks.\n        keypoints (Keypoints, optional): Object containing detected keypoints for each object.\n        speed (dict): Dictionary of preprocess, inference, and postprocess speeds (ms/image).\n        names (dict): Dictionary of class names.\n        path (str): Path to the image file.\n\n    Methods:\n        update(boxes=None, masks=None, probs=None, obb=None): Updates object attributes with new detection results.\n        cpu(): Returns a copy of the Results object with all tensors on CPU memory.\n        numpy(): Returns a copy of the Results object with all tensors as numpy arrays.\n        cuda(): Returns a copy of the Results object with all tensors on GPU memory.\n        to(*args, **kwargs): Returns a copy of the Results object with tensors on a specified device and dtype.\n        new(): Returns a new Results object with the same image, path, and names.\n        plot(...): Plots detection results on an input image, returning an annotated image.\n        show(): Show annotated results to screen.\n        save(filename): Save annotated results to file.\n        verbose(): Returns a log string for each task, detailing detections and classifications.\n        save_txt(txt_file, save_conf=False): Saves detection results to a text file.\n        save_crop(save_dir, file_name=Path(\"im.jpg\")): Saves cropped detection images.\n        tojson(normalize=False): Converts detection results to JSON format.\n    "]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","def zip_folder(folder_path, output_path):\n","    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","        for root, _, files in os.walk(folder_path):\n","            for file in files:\n","                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(folder_path, '..')))\n","\n","folder_path = '/content/runs/detect/train2'  # Path to the folder you want to download\n","output_path = '/content/detect.zip'   # Path for the output zip file\n","zip_folder(folder_path, output_path)\n","\n","from google.colab import files\n","\n","files.download(output_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"qBRzOaueAAOt","executionInfo":{"status":"ok","timestamp":1708211267591,"user_tz":-120,"elapsed":636,"user":{"displayName":"Marios Chartsias","userId":"08266621666467733398"}},"outputId":"e097f752-f195-40dd-bace-a9ba7e8a5c6e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_1aeb802d-24c3-4c11-8b90-e803fa259289\", \"detect.zip\", 14063387)"]},"metadata":{}}]},{"cell_type":"code","source":["for i in result.boxes.xyxy:\n","  print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ytx7QgIMKsAt","executionInfo":{"status":"ok","timestamp":1708175144477,"user_tz":-120,"elapsed":3,"user":{"displayName":"Marios Chartsias","userId":"08266621666467733398"}},"outputId":"c8f1e313-1161-442c-a4e9-bba6b3ef96f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1890.1628,   53.4809, 1919.3049,  345.0317], device='cuda:0')\n","tensor([1303.2501, 1043.6565, 1326.8184, 1066.8275], device='cuda:0')\n","tensor([1893.2651,   85.3783, 1919.2351,  425.8147], device='cuda:0')\n","tensor([1039.0553, 1043.8749, 1063.3949, 1066.4382], device='cuda:0')\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMSPE71/m6zSA1AjIheyz6u"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
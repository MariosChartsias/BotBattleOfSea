{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..\\..\\src') # this ensures that the src models are located to import them bellow\n",
    "#sys.path.append('C:\\\\Users\\\\Marios\\\\Desktop\\\\Μάριος\\\\BotBattleOfSea\\\\src') deprecated absolute path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui  # Import pyautogui for screen capture\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import colors, Annotator\n",
    "from PIL import ImageGrab\n",
    "from win32api import GetSystemMetrics\n",
    "import keyboard #pip install keyboard\n",
    "import time\n",
    "from Paths import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will hardwrite all Tools function because we cant use from docs the function getText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_of_pause=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click(middle_x,middle_y):\n",
    "    pyautogui.click(middle_x, middle_y)\n",
    "    print(\"function: click\") # for debugging only\n",
    "    time.sleep(time_of_pause) # for debugging only\n",
    "\n",
    "\n",
    "def screenshot(x1, y1, x2, y2,i):\n",
    "    # Convert coordinates to integers\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "    # Take a screenshot of the specified region\n",
    "    screenshot = pyautogui.screenshot(region=(x1,y1,x2-x1,y2-y1))\n",
    "\n",
    "    # Save the screenshot\n",
    "    screenshot.save(f'OcrTexts\\screenshot{i}.png')\n",
    "    print(\"function: screenshot\") # for debugging only\n",
    "    time.sleep(time_of_pause) # for debugging only\n",
    "\n",
    "def screenshot_array(x1, y1, x2, y2, i):\n",
    "    # Convert coordinates to integers\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "    \n",
    "    # Expand the region by 5 pixels\n",
    "    x1 -= 5\n",
    "    y1 -= 5\n",
    "    x2 += 5\n",
    "    y2 += 5\n",
    "\n",
    "    # Take a screenshot of the expanded region\n",
    "    screenshot = pyautogui.screenshot(region=(x1, y1, x2 - x1, y2 - y1))\n",
    "    screenshot.save(f'C:\\\\Users\\\\Marios\\\\Desktop\\\\Μάριος\\\\BotBattleOfSea\\\\src\\\\OcrTexts\\\\screenshot{i}.png')\n",
    "\n",
    "    print(\"function: screenshot_array\")  # for debugging only\n",
    "    time.sleep(time_of_pause)  # for debugging only\n",
    "    return np.array(screenshot)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#this absolute path works only for ipynb and not for the actual Tools.py file\n",
    "def getText(screenshot_array_format,modelOCR=YOLO(absolute_path_ocr_model_640px_windows)):\n",
    "    results = modelOCR.predict(screenshot_array_format,imgsz=640, conf=0.2)\n",
    "    boxes = results[0].boxes.xyxy.cpu()\n",
    "    clss = results[0].boxes.cls.cpu().tolist()\n",
    "    Dictionary = results[0].names\n",
    "    mapping = {}\n",
    "    for box, cls in zip(boxes, clss):\n",
    "        mapping[box[0]] = Dictionary[cls][-1]\n",
    "        #print(f\"box={box[0]}, cls={cls}->{Dictionary[cls]}\")\n",
    "    \n",
    "    sorted_dict = {k: v for k, v in sorted(mapping.items(), key=lambda item: item[0])}\n",
    "    string=''\n",
    "    for value in sorted_dict.values():\n",
    "        string=string+value\n",
    "\n",
    "    print(\"function: getText\") # for debugging only\n",
    "    time.sleep(time_of_pause) # for debugging only\n",
    "    return string\n",
    "\n",
    "def mouse_in_safe_zone():\n",
    "    pyautogui.FAILSAFE = False  # Disables the fail-safe feature\n",
    "    pyautogui.moveTo(0, 0, duration=0)\n",
    "    print(\"function: mouse_in_safe_zone\") # for debugging only\n",
    "    time.sleep(time_of_pause) # for debugging only\n",
    "\n",
    "import random\n",
    "\n",
    "def getWidth_Height(x1, x2, y1, y2):\n",
    "    # Ensure x1 < x2 and y1 < y2\n",
    "    x_min, x_max = min(x1, x2), max(x1, x2)\n",
    "    y_min, y_max = min(y1, y2), max(y1, y2)\n",
    "    \n",
    "    Width=x_max-x_min\n",
    "    Height=y_max-y_min\n",
    "\n",
    "    print(\"function: getWidth_Height\") # for debugging only\n",
    "    time.sleep(time_of_pause) # for debugging only\n",
    "    return Width, Height\n",
    "\n",
    "def getMiddle_point(x1, x2, y1, y2):\n",
    "    middle_x = (x1 + x2) / 2\n",
    "    middle_y = (y1 + y2) / 2\n",
    "    \n",
    "    print(\"function: getMiddle_point\") # for debugging only\n",
    "    time.sleep(time_of_pause) # for debugging only\n",
    "    return(middle_x, middle_y)\n",
    "\n",
    "def stableCam():\n",
    "    pyautogui.typewrite('ws')\n",
    "    print(\"function: stableCam\") # for debugging only\n",
    "    time.sleep(time_of_pause) # for debugging only\n",
    "\n",
    "def centerCamera(): # g is default letter for centering the cammera \n",
    "    pyautogui.typewrite('g')\n",
    "    print(\"function: centerCamera\") # for debugging only\n",
    "    time.sleep(time_of_pause) # for debugging only\n",
    "\n",
    "def cartesian_distance(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Calculate the Cartesian distance between two points (x1, y1) and (x2, y2).\n",
    "\n",
    "    Args:\n",
    "    - x1, y1 (float): Coordinates of the first point.\n",
    "    - x2, y2 (float): Coordinates of the second point.\n",
    "\n",
    "    Returns:\n",
    "    - float: The Cartesian distance between the two points.\n",
    "    \"\"\"\n",
    "    print(np.array([x2, y2]).shape, np.array([x1, y1]).shape)\n",
    "    distance = np.linalg.norm(np.array([x2, y2]) - np.array([x1, y1]))\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function bellow is about only to check the results of the OCR detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'): # Adjust file extensions as needed\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "    return images\n",
    "\n",
    "folder_path = r'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\OcrTexts'\n",
    "folder_path_labeled=r'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\Snapshot Storage\\OCR\\Labeled'\n",
    "images = load_images_from_folder(folder_path_labeled)\n",
    "\n",
    "# Now images is a list containing all the loaded images from the folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images: \n",
    "    print(getText(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get Start with the Object Detection System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.14 🚀 Python-3.11.2 torch-2.2.0+cpu CPU (AMD Ryzen 5 2600X Six-Core Processor)\n",
      "Model summary (fused): 168 layers, 3008183 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/4 C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections\\screenshot1.png: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 1 BattleOfSeaWindow, 1 CenterMyBoat, 1 chatButton, 1 glitter, 1 map, 575.9ms\n",
      "image 2/4 C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections\\screenshot2.png: 1152x2016 1 BattleOfSeaExit, 1 BattleOfSeaWindow, 1 CenterMyBoat, 1 chatButton, 2 glitters, 1 glitterOnMap, 1 map, 592.7ms\n",
      "image 3/4 C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections\\screenshot3.png: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 1 BattleOfSeaWindow, 1 CenterMyBoat, 1 chatButton, 1 glitter, 1 glitterOnMap, 1 map, 515.3ms\n",
      "image 4/4 C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections\\screenshot4.png: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 2 BattleOfSeaWindows, 1 CenterMyBoat, 1 chatButton, 2 glitters, 1 map, 516.9ms\n",
      "Speed: 19.8ms preprocess, 550.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1152, 2016)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "4 labels saved to runs\\detect\\predict\\labels\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "#This is for checking how the final results should be displayed\n",
    "!yolo task=detect mode=predict model=\"C:\\\\Users\\\\Marios\\\\Desktop\\\\Μάριος\\\\BotBattleOfSea\\\\src\\\\models\\\\yolov8_2000px.pt\" conf=0.25 source='C:\\\\Users\\\\Marios\\\\Desktop\\\\Μάριος\\\\BotBattleOfSea\\\\src\\\\ObjectDetections' save=True save_txt=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is default way to make a display by using Yolo fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ultralytics YOLOv8.1.14 🚀 Python-3.11.2 torch-2.2.0+cpu CPU (AMD Ryzen 5 2600X Six-Core Processor)\n",
      "Model summary (fused): 168 layers, 3008183 parameters, 0 gradients, 8.1 GFLOPs\n",
      "WARNING ⚠️ imgsz=[2000] must be multiple of max stride 32, updating to [2016]\n",
      "image 1/1 C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections\\image0.png: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 1 BattleOfSeaWindow, 1 CenterMyBoat, 1 chatButton, 2 glitters, 1 glitterClicked, 2 glitterOnMaps, 1 map, 590.2ms\n",
      "Speed: 23.2ms preprocess, 590.2ms inference, 9.8ms postprocess per image at shape (1, 3, 1152, 2016)\n",
      "Results saved to \u001b[1mruns\\detect\\train7\u001b[0m\n",
      "1 label saved to runs\\detect\\train7\\labels\n"
     ]
    }
   ],
   "source": [
    "from ultralytics.models.yolo.detect import DetectionPredictor\n",
    "\n",
    "model_path = \"C:\\\\Users\\\\Marios\\\\Desktop\\\\Μάριος\\\\BotBattleOfSea\\\\src\\\\models\\\\yolov8_2000px.pt\"\n",
    "source_path = \"C:\\\\Users\\\\Marios\\\\Desktop\\\\Μάριος\\\\BotBattleOfSea\\\\src\\\\ObjectDetections\"\n",
    "output_dir = \"C:\\\\Users\\\\Marios\\\\Desktop\\\\Μάριος\\\\BotBattleOfSea\\\\src\\\\Output\"\n",
    "\n",
    "args = dict(model=model_path, source=source_path ,imgsz=2000, save=True, save_txt=True, show_boxes=True) # xywh)\n",
    "predictor = DetectionPredictor(overrides=args)\n",
    "predictor.predict_cli()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a function that will predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ imgsz=[2000] must be multiple of max stride 32, updating to [2016]\n",
      "0: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 3 BattleOfSeaWindows, 1 CenterMyBoat, 1 chatButton, 2 glitterClickeds, 1 glitterOnMap, 1 map, 601.0ms\n",
      "Speed: 33.1ms preprocess, 601.0ms inference, 5.0ms postprocess per image at shape (1, 3, 1152, 2016)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def prepare_model(imgsize):\n",
    "    global model\n",
    "    model = YOLO(absolute_path_object_model_2000px_windows)\n",
    "    folder_path = r'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections'\n",
    "    folder_unlabeled = r'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\Snapshot Storage\\PlayForGlitter\\Unlabeled'\n",
    "    global images_uint8, results , mapped_list\n",
    "    # Load images from folder\n",
    "    images = load_images_from_folder(folder_path)\n",
    "\n",
    "    images_rgb = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in images]\n",
    "    images_uint8 = [img.astype('uint8') for img in images_rgb]\n",
    "\n",
    "    results = model.predict(images_uint8, imgsz=imgsize, conf=0.2)\n",
    "\n",
    "    clss=[]\n",
    "    Dictionary=results[0].names\n",
    "    #print(Dictionary)\n",
    "    for i in range(len(results)):\n",
    "        clss.append(results[i].boxes.cls.cpu().tolist())\n",
    "\n",
    "    mapped_list = []\n",
    "    # Iterate through each sublist in clss\n",
    "    for sublist in clss:\n",
    "        # Create a new sublist with mapped values\n",
    "        mapped_sublist = [f'{int(num)}->' + Dictionary[int(num)] for num in sublist]\n",
    "        # Append the mapped sublist to the mapped list\n",
    "        mapped_list.append(mapped_sublist)\n",
    "\n",
    "prepare_model(2000)\n",
    "\n",
    "#objects: ->Dictionary\n",
    "#  {0:'BattleOfSeaChangeSize',\n",
    "#    1:'BattleOfSeaExit',\n",
    "#      2:'BattleOfSeaWindow',\n",
    "#        3: 'CenterMyBoat',\n",
    "#          4: 'ConfirmToBotQuestion',\n",
    "#            5: 'TextFieldToBotQuestion',\n",
    "#              6: 'chat',\n",
    "#                7: 'chatButton',\n",
    "#                  8: 'glitter',\n",
    "#                    9: 'glitterClicked',\n",
    "#                      10: 'glitterOnMap',\n",
    "#                        11: 'map',\n",
    "#                          12: 'ocrText'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a function to delete the folder of results before from every use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def delete_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Check if the folder exists and delete it if it does.\n",
    "\n",
    "    Args:\n",
    "    - folder_path (str): The path to the folder to be checked and deleted.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if the folder was deleted successfully or didn't exist, False otherwise.\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        try:\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f\"The folder '{folder_path}' has been deleted.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            #print(f\"Error deleting the folder '{folder_path}': {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        #print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return True  # Return True because the folder doesn't exist, no action required\n",
    "\n",
    "# Example usage:\n",
    "folder_path = r'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs'\n",
    "delete_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "[[     935.43      897.89      984.27      946.35     0.94706           3]\n",
      " [       1562      855.08      1578.8      874.83     0.94075           8]\n",
      " [     1761.2      97.592      1888.3      226.05     0.90497          11]\n",
      " [     1844.2      5.2178      1853.8      14.526     0.90404           0]\n",
      " [       1890      4.7828      1900.4      14.488     0.88059           1]\n",
      " [     1724.7      99.541      1752.3      127.69     0.87116           7]\n",
      " [     1415.8       505.5      1425.8      525.27     0.80763           8]\n",
      " [     45.989      9.6984      959.67      915.93     0.79528           2]\n",
      " [     1873.6       177.7      1879.1       184.4     0.64581          10]\n",
      " [     1867.6      163.73        1874      171.02     0.39414          10]\n",
      " [      513.6      272.19      529.34      289.68     0.28827           9]]\n",
      "image 1/1 C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections\\image0.png: 1152x2016 1 BattleOfSeaChangeSize, 1 BattleOfSeaExit, 1 BattleOfSeaWindow, 1 CenterMyBoat, 1 chatButton, 2 glitters, 1 glitterClicked, 2 glitterOnMaps, 1 map, 555.2ms\n",
      "Speed: 24.5ms preprocess, 555.2ms inference, 0.0ms postprocess per image at shape (1, 3, 1152, 2016)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "1 label saved to runs\\detect\\predict\\labels\n"
     ]
    }
   ],
   "source": [
    "# Run batched inference on a list of images\n",
    "model = YOLO(absolute_path_object_model_2000px_windows)\n",
    "\n",
    "folder_path_to_read = r'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections'\n",
    "delete_folder(folder_path)\n",
    "results = model(folder_path_to_read, stream=True , conf=0.25, retina_masks=True , save=True, save_txt=True)  # return a generator of Results objects\n",
    "\n",
    "# Process results generator\n",
    "for result in results:\n",
    "    boxes = result.boxes.cpu().numpy().data # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    print(boxes)\n",
    "    #result.show()  # display to screen\n",
    "    #result.save(filename='result.jpg')  # save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make this function available to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(folder_path_to_read,model=YOLO(absolute_path_object_model_2000px_windows)):\n",
    "    #folder_path_to_read = r'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections'\n",
    "    delete_folder(folder_path)\n",
    "    results = model(folder_path_to_read, stream=True , conf=0.25, retina_masks=True , save=True, save_txt=False )  # returns Results objects\n",
    "    for result in results:\n",
    "        boxes = result.boxes.cpu().numpy().data # Boxes object for bounding box outputs\n",
    "        return boxes\n",
    "\n",
    "def getCenterOfWindow(folder_path_to_read,model=YOLO(absolute_path_object_model_2000px_windows)):\n",
    "    #folder_path_to_read = r'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections'\n",
    "    #delete_folder(folder_path)\n",
    "    results = model(folder_path_to_read, stream=True , conf=0.25, retina_masks=True , save=True, save_txt=False ,imgsz=512)  # returns the middle of the window\n",
    "    for result in results:\n",
    "        boxes = result.boxes.cpu().numpy().data # Boxes object for bounding box outputs\n",
    "    \n",
    "    if boxes.size!=0:\n",
    "        filtered_rows = boxes[boxes[:, 5] == 2] #2 -> BattleOfSeaWindow\n",
    "    if boxes.size!=0 and len(filtered_rows) > 0:\n",
    "        first_row = filtered_rows[0]\n",
    "        #print(\"First row where objects[:,3] == 8:\")\n",
    "        #click(first_row[0],first_row[1])\n",
    "        return((first_row[0]+first_row[2])/2, (first_row[1]+first_row[3])/2)\n",
    "    else:\n",
    "        height, width = GetSystemMetrics(0), GetSystemMetrics(1)\n",
    "        # Set the center point for the visioneye annotation\n",
    "        center_point = (pyautogui.size()[0]/2, pyautogui.size()[1]/2)  # Use the screen height as the y-coordinate\n",
    "        return center_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets create the logic of the bot. We want to find the nearest glitter->8 by the ship (ship will be at the center of the screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "\n",
      "image 1/1 C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections\\image0.png: 288x512 1 BattleOfSeaWindow, 62.1ms\n",
      "Speed: 1.0ms preprocess, 62.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "sorted objects [[     959.85      922.12      382.12           3]\n",
      " [     1420.8      515.38      461.49           8]\n",
      " [     502.83      462.81      463.64           2]\n",
      " [     521.47      280.93      509.34           9]\n",
      " [     1570.4      864.96      691.48           8]\n",
      " [     1738.5      113.62      887.62           7]\n",
      " [     1824.7      161.82      943.83          11]\n",
      " [     1870.8      167.37      984.08          10]\n",
      " [     1876.4      181.05      984.15          10]\n",
      " [       1849      9.8721        1035           0]\n",
      " [     1895.2      9.6353      1075.1           1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "height, width = GetSystemMetrics(0), GetSystemMetrics(1)\n",
    "# Set the center point for the visioneye annotation\n",
    "center_point = (pyautogui.size()[0]/2, pyautogui.size()[1]/2)  # Use the screen height as the y-coordinate\n",
    "\n",
    "\n",
    "\n",
    "img = ImageGrab.grab(bbox=(0,0, pyautogui.size()[0], pyautogui.size()[1]))\n",
    "img_np = np.array(img)\n",
    "screen_bgr = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#objects= predict(screen_bgr)\n",
    "#centerscreen_x, centerscreen_y = getCenterOfWindow(screen_bgr) \n",
    "objects= predict(r'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections') #this is only for debugging purposes\n",
    "centerscreen_x, centerscreen_y = getCenterOfWindow(r'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\src\\ObjectDetections') \n",
    "centerscreen_x, centerscreen_y = center_point\n",
    "\n",
    "\n",
    "objects = objects[:, [0, 1, 2, 3, 5]]\n",
    "\n",
    "# Calculate the center coordinates for each bounding box\n",
    "center_x = (objects[:, 0] + objects[:, 2]) / 2\n",
    "center_y = (objects[:, 1] + objects[:, 3]) / 2\n",
    "\n",
    "# Calculate the Cartesian distance separately\n",
    "centerscreen_array_x = np.array([[centerscreen_x]] * objects.shape[0]).T\n",
    "centerscreen_array_y = np.array([[centerscreen_y]] * objects.shape[0]).T\n",
    "\n",
    "# Calculate the Cartesian distance separately for each pair of points\n",
    "distances = np.linalg.norm(np.column_stack((center_x, center_y)) - np.column_stack((centerscreen_array_x.squeeze(), centerscreen_array_y.squeeze())), axis=1)\n",
    "\n",
    "# Create the new array with center coordinates and object number\n",
    "objects = np.column_stack((center_x, center_y, distances, objects[:, 4]))\n",
    "\n",
    "if objects.size!=0:\n",
    "    # Assuming objects is your NumPy array\n",
    "    sorted_indices = np.argsort(objects[:, 2])\n",
    "\n",
    "    # Use the sorted indices to rearrange the rows of the array\n",
    "    sorted_objects = objects[sorted_indices]\n",
    "\n",
    "    print(f'sorted objects {sorted_objects}\\n')\n",
    "    # Assuming objects is your NumPy array\n",
    "    filtered_rows = objects[objects[:, 3] == 8]\n",
    "\n",
    "    if len(filtered_rows) > 0:\n",
    "        first_row = filtered_rows[0]\n",
    "        #print(\"First row where objects[:,3] == 8:\")\n",
    "        #click(first_row[0],first_row[1])\n",
    "        pyautogui.moveTo(first_row[0],first_row[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the loop that will of automated visual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True\n",
    "while run:\n",
    "    img = ImageGrab.grab(bbox=(0,0, width, height))\n",
    "    img_np = np.array(img)\n",
    "    screen_bgr = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    objects= predict(screen_bgr)\n",
    "    centerscreen_x, centerscreen_y = getCenterOfWindow(screen_bgr) \n",
    "\n",
    "    objects = objects[:, [0, 1, 2, 3, 5]]\n",
    "\n",
    "    # Calculate the center coordinates for each bounding box\n",
    "    center_x = (objects[:, 0] + objects[:, 2]) / 2\n",
    "    center_y = (objects[:, 1] + objects[:, 3]) / 2\n",
    "\n",
    "    # Calculate the Cartesian distance separately\n",
    "    centerscreen_array_x = np.array([[centerscreen_x]] * objects.shape[0]).T\n",
    "    centerscreen_array_y = np.array([[centerscreen_y]] * objects.shape[0]).T\n",
    "\n",
    "    # Calculate the Cartesian distance separately for each pair of points\n",
    "    distances = np.linalg.norm(np.column_stack((center_x, center_y)) - np.column_stack((centerscreen_array_x.squeeze(), centerscreen_array_y.squeeze())), axis=1)\n",
    "\n",
    "    # Create the new array with center coordinates and object number\n",
    "    objects = np.column_stack((center_x, center_y, distances, objects[:, 4]))\n",
    "\n",
    "    if objects.size!=0:\n",
    "        # Assuming objects is your NumPy array\n",
    "        sorted_indices = np.argsort(objects[:, 2])\n",
    "\n",
    "        # Use the sorted indices to rearrange the rows of the array\n",
    "        sorted_objects = objects[sorted_indices]\n",
    "\n",
    "        print(f'sorted objects {sorted_objects}\\n')\n",
    "        # Assuming objects is your NumPy array\n",
    "        filtered_rows = objects[objects[:, 3] == 8]\n",
    "\n",
    "        print(f'filtered rows = {filtered_rows} and filtered_rows.size = {filtered_rows.size}')\n",
    "        if len(filtered_rows) > 0:\n",
    "            first_row = filtered_rows[0]\n",
    "            #print(\"First row where objects[:,3] == 8:\")\n",
    "            click(first_row[0],first_row[1])\n",
    "            #pyautogui.moveTo(first_row[0],first_row[1])\n",
    "        else:\n",
    "             print('no glitter')\n",
    "    if keyboard.is_pressed('esc'):\n",
    "            print(\"Stop Loop!\")\n",
    "            run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make sure to center the boat and be more automated instead of just clicking on the nearest from windows center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "\n",
      "0: 288x512 (no detections), 137.6ms\n",
      "Speed: 12.0ms preprocess, 137.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "\n",
      "0: 288x512 (no detections), 69.6ms\n",
      "Speed: 2.0ms preprocess, 69.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "\n",
      "0: 288x512 (no detections), 69.1ms\n",
      "Speed: 0.6ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "\n",
      "0: 288x512 (no detections), 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "\n",
      "0: 288x512 (no detections), 71.1ms\n",
      "Speed: 2.0ms preprocess, 71.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "\n",
      "0: 288x512 (no detections), 78.1ms\n",
      "Speed: 2.0ms preprocess, 78.1ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "\n",
      "0: 288x512 (no detections), 73.1ms\n",
      "Speed: 1.0ms preprocess, 73.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "\n",
      "0: 288x512 (no detections), 66.1ms\n",
      "Speed: 1.0ms preprocess, 66.1ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "\n",
      "0: 288x512 1 BattleOfSeaWindow, 67.1ms\n",
      "Speed: 2.0ms preprocess, 67.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "sorted objects [[     1013.9      531.58      61.181           8]\n",
      " [     929.39      463.06      73.463           2]\n",
      " [     959.85       922.1      389.46           3]\n",
      " [     472.33      462.21      485.57           2]\n",
      " [     256.23      532.34      696.52           8]\n",
      " [     1738.4      113.49      890.51           7]\n",
      " [     98.917      923.34      938.95           8]\n",
      " [     1824.6      161.36      947.66          11]\n",
      " [       1849      9.8608      1037.6           0]\n",
      " [     1895.2      9.6524      1077.9           1]]\n",
      "\n",
      "function: stableCam\n",
      "function: click\n",
      "function: mouse_in_safe_zone\n",
      "glitter_rows rows = [[     1013.9      531.58      61.181           8]\n",
      " [     98.917      923.34      938.95           8]\n",
      " [     256.23      532.34      696.52           8]] and glitter_rows.size = 12\n",
      "The folder 'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\runs' has been deleted.\n",
      "\n",
      "\n",
      "0: 288x512 1 BattleOfSeaWindow, 1 glitterClicked, 67.1ms\n",
      "Speed: 2.0ms preprocess, 67.1ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "sorted objects [[     1013.9      540.17      65.851           9]\n",
      " [     959.87      462.82      73.683           2]\n",
      " [     959.86      922.15      386.75           3]\n",
      " [     472.23      461.99      481.62           2]\n",
      " [     256.27       539.5      691.95           8]\n",
      " [     1738.2      113.53       895.7           7]\n",
      " [     98.868      931.23      936.97           8]\n",
      " [     1824.7      161.41      953.01          11]\n",
      " [       1849      9.8571        1043           0]\n",
      " [     1895.2      9.6575      1083.2           1]]\n",
      "\n",
      "function: stableCam\n"
     ]
    }
   ],
   "source": [
    "run = True\n",
    "\n",
    "while run:\n",
    "    img = ImageGrab.grab(bbox=(0,0, pyautogui.size()[0], pyautogui.size()[1]))\n",
    "    img_np = np.array(img)\n",
    "    screen_bgr = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    objects= predict(screen_bgr)\n",
    "    centerscreen_x, centerscreen_y = getCenterOfWindow(screen_bgr) \n",
    "\n",
    "    objects = objects[:, [0, 1, 2, 3, 5]]\n",
    "\n",
    "    # Calculate the center coordinates for each bounding box\n",
    "    center_x = (objects[:, 0] + objects[:, 2]) / 2\n",
    "    center_y = (objects[:, 1] + objects[:, 3]) / 2\n",
    "\n",
    "    # Calculate the Cartesian distance separately\n",
    "    centerscreen_array_x = np.array([[centerscreen_x]] * objects.shape[0]).T\n",
    "    centerscreen_array_y = np.array([[centerscreen_y]] * objects.shape[0]).T\n",
    "\n",
    "    # Calculate the Cartesian distance separately for each pair of points\n",
    "    distances = np.linalg.norm(np.column_stack((center_x, center_y)) - np.column_stack((centerscreen_array_x.squeeze(), centerscreen_array_y.squeeze())), axis=1)\n",
    "\n",
    "    # Create the new array with center coordinates and object number\n",
    "    objects = np.column_stack((center_x, center_y, distances, objects[:, 4]))\n",
    "\n",
    "    if objects.size!=0:\n",
    "        # Assuming objects is your NumPy array\n",
    "        sorted_indices = np.argsort(objects[:, 2])\n",
    "        # Use the sorted indices to rearrange the rows of the array\n",
    "        sorted_objects = objects[sorted_indices]\n",
    "\n",
    "        print(f'sorted objects {sorted_objects}\\n')\n",
    "        # Assuming objects is your NumPy array\n",
    "\n",
    "        glitter_rows = objects[objects[:, 3] == 8]\n",
    "        glitterClicked_rows = objects[objects[:, 3] == 9]\n",
    "        CenterMyBoat_rows = objects[objects[:,3] == 3]\n",
    "        ocrText_rows = objects[objects[:,3] == 12]\n",
    "        TextFieldToBotQuestion_rows = objects[objects[:,3] ==5]\n",
    "        ConfirmToBotQuestion = objects[objects[:,3] ==4]\n",
    "\n",
    "        \n",
    "        #if(len(CenterMyBoat_rows)==0 and len(glitterClicked_rows)!=0 and len(glitter_rows) > 0):\n",
    "             \n",
    "\n",
    "        if len(glitterClicked_rows)==0 or len(glitter_rows) > 0:\n",
    "            stableCam()\n",
    "            if len(glitterClicked_rows)>0:\n",
    "                break\n",
    "\n",
    "            if len(glitter_rows) > 0:\n",
    "                time.sleep(2) # this is to avoid the click instantly to another glitter and miss the clicked one\n",
    "                first_row = glitter_rows[0]\n",
    "                click(first_row[0],first_row[1])\n",
    "                mouse_in_safe_zone()\n",
    "                #pyautogui.moveTo(first_row[0],first_row[1])\n",
    "            \n",
    "        elif len(CenterMyBoat_rows)!=0:\n",
    "             centerCamera()\n",
    "             time.sleep(1)\n",
    "\n",
    "        #  0:'BattleOfSeaChangeSize',\n",
    "        #  1:'BattleOfSeaExit',\n",
    "        #  2:'BattleOfSeaWindow',\n",
    "        #  3: 'CenterMyBoat',\n",
    "        #  4: 'ConfirmToBotQuestion',\n",
    "        #  5: 'TextFieldToBotQuestion',\n",
    "        #  6: 'chat',\n",
    "        #  7: 'chatButton',\n",
    "        #  8: 'glitter',\n",
    "        #  9: 'glitterClicked',\n",
    "        #  10: 'glitterOnMap',\n",
    "        #  11: 'map',\n",
    "        #  12: 'ocrText'}\n",
    "        \n",
    "\n",
    "        print(f'glitter_rows rows = {glitter_rows} and glitter_rows.size = {glitter_rows.size}')\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    if keyboard.is_pressed('esc'):\n",
    "            print(\"Stop Loop!\")\n",
    "            run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Axes' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[298], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m         axs[i]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 13\u001b[0m \u001b[43mshow_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_uint8\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[298], line 8\u001b[0m, in \u001b[0;36mshow_images\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m      5\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, num_images, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))  \u001b[38;5;66;03m# Adjust figsize as needed\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_images):\n\u001b[1;32m----> 8\u001b[0m     \u001b[43maxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(images[i])\n\u001b[0;32m      9\u001b[0m     axs[i]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Axes' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(images):\n",
    "    num_images = len(images)\n",
    "    fig, axs = plt.subplots(1, num_images, figsize=(10, 5))  # Adjust figsize as needed\n",
    "\n",
    "    for i in range(num_images):\n",
    "        axs[i].imshow(images[i])\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_images(images_uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def plot_boxes_and_save(images, results, output_dir, dpi=100):\n",
    "    order = 0\n",
    "    for i, (image, result) in enumerate(zip(images, results)):\n",
    "        # Create a new figure\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        # Plot the image\n",
    "        ax.imshow(image)\n",
    "\n",
    "        # Plot each bounding box\n",
    "        for box, name in zip(result.boxes.xyxy, result.names):\n",
    "            x1, y1, x2, y2 = box[:4]\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "\n",
    "            # Create a rectangle patch\n",
    "            rect = patches.Rectangle((x1, y1), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "            # Add the rectangle patch to the Axes\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "            # Add class label as text\n",
    "            ax.text(x1, y1, name, color='r', verticalalignment='top')\n",
    "\n",
    "        # Set axis off\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Save the figure as PNG with specified DPI\n",
    "        plt.savefig(f'{output_dir}/box_{i}.png', bbox_inches='tight', pad_inches=0, dpi=dpi)\n",
    "\n",
    "        print(mapped_list[order])\n",
    "        order += 1\n",
    "        plt.show()\n",
    "        \n",
    "        # Close the figure to release memory\n",
    "        plt.close()\n",
    "\n",
    "# Example usage:\n",
    "output_dir = r'C:\\Users\\Marios\\Desktop\\Μάριος\\BotBattleOfSea\\docs\\src\\ObjectDetectionsPlots'  # Directory to save the plots\n",
    "plot_boxes_and_save(images_uint8, results, output_dir, dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1632x928 (no detections), 440.4ms\n",
      "Speed: 18.0ms preprocess, 440.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 55.0ms\n",
      "Speed: 1.0ms preprocess, 55.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 403.6ms\n",
      "Speed: 15.0ms preprocess, 403.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 52.9ms\n",
      "Speed: 2.5ms preprocess, 52.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 403.6ms\n",
      "Speed: 15.0ms preprocess, 403.6ms inference, 1.6ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 410.5ms\n",
      "Speed: 16.0ms preprocess, 410.5ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 67.0ms\n",
      "Speed: 1.0ms preprocess, 67.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 419.4ms\n",
      "Speed: 16.0ms preprocess, 419.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 57.1ms\n",
      "Speed: 1.0ms preprocess, 57.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 460.5ms\n",
      "Speed: 15.5ms preprocess, 460.5ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 420.2ms\n",
      "Speed: 16.0ms preprocess, 420.2ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.6ms\n",
      "Speed: 2.0ms preprocess, 51.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 404.4ms\n",
      "Speed: 15.0ms preprocess, 404.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 411.0ms\n",
      "Speed: 15.0ms preprocess, 411.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 54.0ms\n",
      "Speed: 1.0ms preprocess, 54.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 406.8ms\n",
      "Speed: 15.0ms preprocess, 406.8ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 52.0ms\n",
      "Speed: 2.0ms preprocess, 52.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 391.4ms\n",
      "Speed: 15.0ms preprocess, 391.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 52.0ms\n",
      "Speed: 2.0ms preprocess, 52.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 394.2ms\n",
      "Speed: 15.0ms preprocess, 394.2ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 52.0ms\n",
      "Speed: 1.0ms preprocess, 52.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 392.4ms\n",
      "Speed: 16.0ms preprocess, 392.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 396.0ms\n",
      "Speed: 15.0ms preprocess, 396.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 50.1ms\n",
      "Speed: 2.0ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 392.3ms\n",
      "Speed: 15.0ms preprocess, 392.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 50.6ms\n",
      "Speed: 2.0ms preprocess, 50.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 396.7ms\n",
      "Speed: 15.0ms preprocess, 396.7ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.6ms\n",
      "Speed: 1.0ms preprocess, 53.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 432.4ms\n",
      "Speed: 16.0ms preprocess, 432.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.6ms\n",
      "Speed: 1.0ms preprocess, 51.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 397.1ms\n",
      "Speed: 15.0ms preprocess, 397.1ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 (no detections), 404.4ms\n",
      "Speed: 15.5ms preprocess, 404.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.1ms\n",
      "Speed: 1.0ms preprocess, 53.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaWindow, 393.2ms\n",
      "Speed: 16.0ms preprocess, 393.2ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 52.0ms\n",
      "Speed: 2.0ms preprocess, 52.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=330.0098571777344, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 (no detections), 411.3ms\n",
      "Speed: 15.6ms preprocess, 411.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaWindow, 3 glitters, 397.9ms\n",
      "Speed: 16.0ms preprocess, 397.9ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 1 BattleOfSeaWindow, 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=91.52989959716797, cls=8.0->glitter\n",
      "function: stableCam\n",
      "function: click\n",
      "function: mouse_in_safe_zone\n",
      "**************detection********************box=18.41689109802246, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=717.3850708007812, cls=8.0->glitter\n",
      "function: stableCam\n",
      "function: click\n",
      "function: mouse_in_safe_zone\n",
      "**************detection********************box=560.8896484375, cls=8.0->glitter\n",
      "function: stableCam\n",
      "function: click\n",
      "function: mouse_in_safe_zone\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaExit, 1 BattleOfSeaWindow, 1 glitter, 404.4ms\n",
      "Speed: 17.0ms preprocess, 404.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 52.1ms\n",
      "Speed: 1.0ms preprocess, 52.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.240966796875, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=1053.12060546875, cls=8.0->glitter\n",
      "function: stableCam\n",
      "function: click\n",
      "function: mouse_in_safe_zone\n",
      "**************detection********************box=930.61279296875, cls=1.0->BattleOfSeaExit\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaWindow, 1 glitter, 404.1ms\n",
      "Speed: 14.0ms preprocess, 404.1ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=1050.388916015625, cls=8.0->glitter\n",
      "function: stableCam\n",
      "function: click\n",
      "function: mouse_in_safe_zone\n",
      "**************detection********************box=960.0418090820312, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaWindow, 407.4ms\n",
      "Speed: 14.0ms preprocess, 407.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 54.0ms\n",
      "Speed: 1.0ms preprocess, 54.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.0620727539062, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 397.7ms\n",
      "Speed: 13.0ms preprocess, 397.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.8ms\n",
      "Speed: 1.0ms preprocess, 51.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.3184814453125, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=361.4377746582031, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 404.4ms\n",
      "Speed: 13.0ms preprocess, 404.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.1ms\n",
      "Speed: 2.0ms preprocess, 51.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.3109130859375, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=363.8827209472656, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 397.0ms\n",
      "Speed: 13.0ms preprocess, 397.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.293701171875, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=363.31585693359375, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 404.6ms\n",
      "Speed: 14.0ms preprocess, 404.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 52.0ms\n",
      "Speed: 2.0ms preprocess, 52.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.3317260742188, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=363.39306640625, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 404.4ms\n",
      "Speed: 13.1ms preprocess, 404.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.8ms\n",
      "Speed: 2.3ms preprocess, 53.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.342041015625, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=363.2063903808594, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 404.3ms\n",
      "Speed: 12.0ms preprocess, 404.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.3770751953125, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=367.684814453125, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 412.1ms\n",
      "Speed: 13.0ms preprocess, 412.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 54.0ms\n",
      "Speed: 1.0ms preprocess, 54.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.50537109375, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=362.80572509765625, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaWindow, 402.4ms\n",
      "Speed: 13.0ms preprocess, 402.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.3871459960938, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaWindow, 408.0ms\n",
      "Speed: 12.3ms preprocess, 408.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.4027099609375, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaWindow, 400.4ms\n",
      "Speed: 12.0ms preprocess, 400.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.3701782226562, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaExit, 2 BattleOfSeaWindows, 414.3ms\n",
      "Speed: 13.0ms preprocess, 414.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.3719482421875, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=79.94284057617188, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=930.56005859375, cls=1.0->BattleOfSeaExit\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaExit, 2 BattleOfSeaWindows, 400.6ms\n",
      "Speed: 14.0ms preprocess, 400.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 50.1ms\n",
      "Speed: 2.0ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.4559936523438, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=78.33869171142578, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=930.6620483398438, cls=1.0->BattleOfSeaExit\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 421.6ms\n",
      "Speed: 15.0ms preprocess, 421.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.6393432617188, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=94.40241241455078, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaWindow, 412.7ms\n",
      "Speed: 15.0ms preprocess, 412.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.6ms\n",
      "Speed: 1.0ms preprocess, 51.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.6093139648438, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 416.3ms\n",
      "Speed: 15.0ms preprocess, 416.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.5819091796875, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=94.45326232910156, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 409.3ms\n",
      "Speed: 16.0ms preprocess, 409.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.62353515625, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=94.3443374633789, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 409.3ms\n",
      "Speed: 15.0ms preprocess, 409.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.6380615234375, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=95.03820037841797, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 405.1ms\n",
      "Speed: 16.1ms preprocess, 405.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.2ms\n",
      "Speed: 1.0ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.6483764648438, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=95.66915893554688, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 2 BattleOfSeaWindows, 418.4ms\n",
      "Speed: 15.5ms preprocess, 418.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.5916748046875, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=94.10881042480469, cls=2.0->BattleOfSeaWindow\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaExit, 1 BattleOfSeaWindow, 405.4ms\n",
      "Speed: 15.0ms preprocess, 405.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.7333984375, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=930.646240234375, cls=1.0->BattleOfSeaExit\n",
      "\n",
      "0: 1632x928 1 BattleOfSeaExit, 1 BattleOfSeaWindow, 428.1ms\n",
      "Speed: 13.0ms preprocess, 428.1ms inference, 1.0ms postprocess per image at shape (1, 3, 1632, 928)\n",
      "\n",
      "WARNING ⚠️ imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "0: 384x224 (no detections), 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 224)\n",
      "**************detection********************box=960.2867431640625, cls=2.0->BattleOfSeaWindow\n",
      "**************detection********************box=930.6303100585938, cls=1.0->BattleOfSeaExit\n",
      "Stop Loop!\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(absolute_path_object_model_2000px_windows)\n",
    "names = model.model.names\n",
    "\n",
    "text=''\n",
    "confirm=False\n",
    "enable_to_click_glitter=True\n",
    "click_next_glitter=True\n",
    "navigation=False\n",
    "height, width = GetSystemMetrics(0), GetSystemMetrics(1)\n",
    "# Set the center point for the visioneye annotation\n",
    "center_point = (-10, pyautogui.size()[1])  # Use the screen height as the y-coordinate\n",
    "\n",
    "run=True\n",
    "i=1\n",
    "while run:\n",
    "\n",
    "    img = ImageGrab.grab(bbox=(0,0, width, height))\n",
    "    img_np = np.array(img)\n",
    "    screen_bgr = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Predict objects in the screenshot using the YOLO model\n",
    "    results = model.predict(screen_bgr, conf=0.2)\n",
    "    boxes = results[0].boxes.xyxy.cpu()\n",
    "    clss = results[0].boxes.cls.cpu().tolist()\n",
    "    Dictionary = results[0].names\n",
    "\n",
    "\n",
    "    #prediction for Navigation\n",
    "    resultsNavigation = model.predict(screen_bgr , imgsz=360, conf=0.2)\n",
    "    boxesNavigation = results[0].boxes.xyxy.cpu()\n",
    "    clssNavigation = results[0].boxes.cls.cpu().tolist()\n",
    "    DictionaryNavigation = results[0].names\n",
    "\n",
    "\n",
    "\n",
    "    #print(Dictionary.items())\n",
    "    # Annotate the screenshot with bounding boxes and class labels\n",
    "    annotator = Annotator(screen_bgr, line_width=2)\n",
    "    for box, cls in zip(boxes, clss):\n",
    "        #print(f\"box={box}\")\n",
    "        #print(f\"cls={cls}->{Dictionary[cls]}\")\n",
    "        print(f\"**************detection********************box={box[0]}, cls={cls}->{Dictionary[cls]}\")   \n",
    "        time.sleep(time_of_pause) # for debugging only\n",
    "\n",
    "        if(cls==12.0): #12: ocrText\n",
    "            #print(f'box[0]={box[0]},box[1]={box[1]},box[2]={box[2]},box[3]={box[3]}')\n",
    "            Numbers=screenshot_array(box[0],box[1],box[2],box[3],i)\n",
    "            text=getText(Numbers)\n",
    "            i=i+1\n",
    "            print(f'text={text} and object={Dictionary[cls]}')\n",
    "        ##################################################################        OCR CAPTURE CODE       ###########################################################################\n",
    "        if(cls==5.0 and text!=''): #5.0: TextFieldToBotQuestion\n",
    "            click(box[0],box[2],box[1],box[3])   \n",
    "            time.sleep(1) \n",
    "            pyautogui.typewrite(text)\n",
    "            time.sleep(1)\n",
    "            text=''\n",
    "            print(f'text={text}')\n",
    "            confirm=True\n",
    "            #run = False   \n",
    "        if(cls==4.0 and confirm): #4.0: ConfirmToBotQuestion\n",
    "            confirm=False\n",
    "            click(box[0],box[2],box[1],box[3])\n",
    "        #############################################################################################################################################################################\n",
    "        if(cls==9.0): #9.0: glitterClicked\n",
    "            centerCamera()\n",
    "            time.sleep(2) \n",
    "            break\n",
    "        elif(cls==8.0): #8.0: glitter\n",
    "            stableCam()\n",
    "            click(box[0],box[2],box[1],box[3])\n",
    "            mouse_in_safe_zone()\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "                \n",
    "            \n",
    "\n",
    "        annotator.box_label(box, label=names[int(cls)], color=colors(int(cls)))\n",
    "        annotator.visioneye(box, center_point)\n",
    "\n",
    "    if keyboard.is_pressed('esc'):\n",
    "            print(\"Stop Loop!\")\n",
    "            run = False\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
